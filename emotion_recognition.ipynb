{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emotion_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surekhag28/DeepLearning_Projects/blob/master/emotion_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U-l0Ymx7yOO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6bfca4a6-c8a0-4490-db06-e25a88c92419"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id6QW2p0A0bE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c695b2e1-7597-4c91-d07c-c49d4583f5de"
      },
      "source": [
        "cd /content/gdrive/My Drive/classifier"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/classifier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0Vlpp64BBgA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "e19c9033-9e05-4507-ed1e-28cc153ac987"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('../data/train_labels.csv')\n",
        "print(df.head())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0                   Image  Category  ...  Fear  Pain  Suffering\n",
            "0           0  007eear5kx5qhbzewz.jpg         0  ...     0     0          0\n",
            "1           1  007eear5kx5qhbzewz.jpg         0  ...     0     0          0\n",
            "2           2  00qbvchuemlwx6muhk.jpg         0  ...     0     0          0\n",
            "3           3  00ypqjg7ig0ocbl6s2.jpg         0  ...     0     0          0\n",
            "4           4  0185j147iy2lwsq0p9.jpg         0  ...     0     0          0\n",
            "\n",
            "[5 rows x 29 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRNxEkW_hpsH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "55522c38-7f6f-45dc-e1ce-61108a87b94c"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from EmotionDataset import EmotionDataset\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "NUM_CLASSES = 26\n",
        "num_epochs = 5\n",
        "\n",
        "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(dev)\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize([224,224]),\n",
        "                                transforms.Grayscale(3),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.5],std=[0.5])\n",
        "                            ])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.5],std=[0.5])\n",
        "                            ])\n",
        "\n",
        "train_data = EmotionDataset(csv_file = '../data/train_labels.csv',\n",
        "                                    root_dir = '../data/train/', transform = transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=20, shuffle=True, num_workers=1)\n",
        "\n",
        "val_data = EmotionDataset(csv_file = '../data/val_labels.csv',\n",
        "                                    root_dir = '../data/val/', transform = transform)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=20, shuffle=True, num_workers=1)\n",
        "\n",
        "test_data = EmotionDataset(csv_file = '../data/test_labels.csv',\n",
        "                                    root_dir = '../data/test/', transform = transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=20, shuffle=True, num_workers=1)\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet,self).__init__()\n",
        "        self.num_classes=NUM_CLASSES\n",
        "        self.conv1 = nn.Conv2d(3,48,kernel_size=5,padding=2)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2),stride=2)\n",
        "        self.conv2 = nn.Conv2d(48,64,kernel_size=5,padding=2)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "        self.conv3 = nn.Conv2d(64,128,kernel_size=5,padding=2)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "        self.fc1 = nn.Linear(28*28*128,2048)\n",
        "        self.fc2 = nn.Linear(2048,NUM_CLASSES)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.relu(self.pool1(self.conv1(x)))  #input: 224*224\n",
        "        x = self.relu(self.pool2(self.conv2(x)))  #input 112*112\n",
        "        x = self.relu(self.pool3(self.conv3(x)))  #input 56*56\n",
        "        x = x.view(-1,28*28*128)             #28*28\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.sigmoid(self.fc2(x))                            #output: 252\n",
        "        return x\n",
        "\n",
        "model = ConvNet()\n",
        "model = model.to(dev)\n",
        "#criterion = nn.MultiLabelMarginLoss()\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(),0.1,momentum=0.9)\n",
        "\n",
        "total_step = len(train_loader)\n",
        "train_losses, val_losses, train_accs, val_acc, train_precs, val_precs, train_recs, val_recs = [],[],[],[],[],[],[],[]\n",
        "\n",
        "classes = {0:'Peac' , 1:'Affection',  2:'Esteem', 3: 'Anticipation', 4:'Engagement', 5:'Confidence', 6:'Happiness', 7:'Pleasure', 8:'Excitement', 9:'Surprise', 10:'Sympathy', 11:'Doubt/Confusion', 12:'Disconnection', 13:'Fatigue', 14:'Embarrassment', 15:'Yearning', 16:'Disapproval', 17:'Aversion',  18:'Annoyance', 19:'Anger', 20:'Sensitivity', 21:'Sadness', 22:'Disquietment', 23:'Fear', 24:'Pain', 25:'Suffering'}\n",
        "\n",
        "correct, pred_positive, pred_negative, class_precision, class_recall  = {},{},{},{},{}\n",
        "\n",
        "def init():\n",
        "    for i in range(26):\n",
        "        correct[i] = 0\n",
        "        pred_positive[i] = 0\n",
        "        pred_negative[i] = 0\n",
        "\n",
        "def calculate_scores(outputs, labels):\n",
        "    predicted = torch.zeros([20,26])\n",
        "    init()\n",
        "\n",
        "    labels = labels.reshape((-1,26))\n",
        "    for i in range(labels.shape[0]):\n",
        "        for j in range(labels.shape[1]):\n",
        "            if (outputs[i][j] > 0.4000):\n",
        "                predicted[i][j] = 1.\n",
        "            if (predicted[i][j] == labels[i][j].to('cpu').float()):\n",
        "                correct[j] += 1\n",
        "            if (predicted[i][j] == 1. and labels[i][j].to('cpu').float() == 0.):\n",
        "                pred_positive[j] += 1\n",
        "            if (predicted[i][j] == 0. and labels[i][j].to('cpu').float() == 1.):\n",
        "                pred_negative[j] += 1\n",
        "\n",
        "\n",
        "    return\n",
        "\n",
        "def calculate_precision():\n",
        "\n",
        "    for i in range(26):\n",
        "        if((correct[i] + pred_positive[i]) == 0):\n",
        "            #print(correct[i] + pred_positive[i])\n",
        "            continue\n",
        "        class_precision[i] += correct[i] / (correct[i] + pred_positive[i])\n",
        "    return class_precision\n",
        "\n",
        "def calculate_recall():\n",
        "    for i in range(26):\n",
        "        if((correct[i] + pred_negative[i]) == 0):\n",
        "          #print(correct[i] + pred_negative[i])\n",
        "            continue\n",
        "        class_recall[i] += correct[i] / (correct[i] + pred_negative[i])\n",
        "    return class_recall\n",
        "\n",
        "def mean_precision(precs):\n",
        "   # for k,v in precs.items():\n",
        "    print(precs)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, val_loss, train_acc, val_acc = 0,0,0,0\n",
        "    for i in range(26):\n",
        "        class_precision[i] = 0\n",
        "        class_recall[i] = 0\n",
        "    for images,labels in train_loader:\n",
        "        images = images.to(dev)\n",
        "        labels = labels.to(dev)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels.type(torch.FloatTensor).to(dev))\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        calculate_scores(outputs, labels)\n",
        "        train_prec = calculate_precision()\n",
        "        train_rec = calculate_recall()\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for i in range(26):\n",
        "                class_precision[i] = 0\n",
        "                class_recall[i] = 0\n",
        "            for images,labels in val_loader:\n",
        "                images = images.to(dev)\n",
        "                labels = labels.to(dev)\n",
        "\n",
        "                val_out = model(images)\n",
        "                loss = criterion(val_out, labels.type(torch.FloatTensor).to(dev))\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                calculate_scores(val_out, labels)\n",
        "                val_prec = calculate_precision()\n",
        "                val_rec = calculate_recall()\n",
        "        model.train()\n",
        "\n",
        "        train_prec = {k: round(v / len(train_loader),3) for k, v in train_prec.items()}\n",
        "        val_prec = {k: round(v / len(val_loader),3) for k, v in val_prec.items()}\n",
        "        train_rec = {k: round(v / len(train_loader),3) for k, v in train_rec.items()}\n",
        "        val_rec = {k: round(v / len(val_loader),3) for k, v in val_rec.items()}\n",
        "    print(\"Epoch: {}/{}.. \".format(epoch, num_epochs),\n",
        "              \"Training Loss: {:.3f}.. \".format(train_loss/len(train_loader)),\n",
        "              \"Validation Loss: {:.3f}.. \".format(val_loss/len(val_loader)))\n",
        "\n",
        "    #print(\"Class wise precision for training set: {}\".format(train_prec))\n",
        "    #print(\"Class wise precision for validation set: {}\".format(val_prec))\n",
        "    #print(\"Class wise recall for training set: {}\".format(train_rec))\n",
        "    #print(\"Class wise recall for validation set: {}\".format(val_rec))\n",
        "    train_losses.append(train_loss/len(train_loader))\n",
        "    val_losses.append(val_loss/len(val_loader))\n",
        "    train_precs.append(train_prec)\n",
        "    val_precs.append(val_prec)\n",
        "    train_recs.append(train_rec)\n",
        "    val_recs.append(val_rec)\n",
        "\n",
        "    #mean_precision(val_precs)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i in range(26):\n",
        "        class_precision[i] = 0\n",
        "        class_recall[i] = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(dev)\n",
        "        labels = labels.to(dev)\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        calculate_scores(outputs, labels)\n",
        "        test_prec = calculate_precision()\n",
        "        test_rec = calculate_recall()\n",
        "    test_prec = {k: round(v / len(test_loader),3) for k, v in test_prec.items()}\n",
        "    test_rec = {k: round(v / len(test_loader),3) for k, v in test_rec.items()}\n",
        "\n",
        "print('Test precision of the model on the 10000 test images: ', test_prec)\n",
        "print('Test recall of the model on the 10000 test images: ', test_rec)\n",
        "#print(mean_precision(test_prec))        \n",
        "                            "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-af724406c211>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mclass_precision\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mclass_recall\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KeyError:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 99, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 99, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/content/gdrive/My Drive/classifier/EmotionDataset.py\", line 33, in __getitem__\n    image = Image.open(img_name)\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2530, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: '../data/train/COCO_train2014_000000119647.jpg'\n"
          ]
        }
      ]
    }
  ]
}